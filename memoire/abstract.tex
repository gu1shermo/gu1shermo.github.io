% Keywords command
\providecommand{\keywordsFR}[1]
{
  \small	
  \textbf{\textit{Mots-clés---}} #1
}

\renewcommand{\abstractnamefont}{\normalfont\Large\bfseries}
%\renewcommand{\abstracttextfont}{\normalfont\Huge}
\renewcommand{\abstractname}{Résumé}


\begin{abstract}
\hskip7mm
\begin{spacing}{1.3}
Ce mémoire explore l'interaction entre la musique codée en direct et la programmation de \textit{shaders} en temps réel. Ce projet découle de l'observation des performances des artistes \textit{livecoders}, où l'interaction entre la musique et les \textit{shaders} semble artificielle, avec les ajustements des variables visuelles pour correspondre au tempo musical.
Pour mieux comprendre l'esprit de la \textit{demoscene}, j'ai d'abord étudié son évolution historique. Ensuite, j'ai exploré les concepts fondamentaux nécessaires au développement de \textit{shaders} en temps réel, avant d'aborder des techniques avancées qui, bien que plus complexes à mettre en œuvre en direct, améliorent considérablement le rendu visuel.
Enfin, ce mémoire examine le défi de l'intégration harmonieuse entre la musique et les \textit{shaders}. À travers une étude approfondie des interactions entre les composantes sonores et visuelles, et en utilisant Orca et FoxDot pour générer un flux MIDI et contrôler les \textit{shaders}, cette recherche vise à ouvrir de nouveaux horizons pour l'exploration créative dans le domaine de la \textit{demoscene} et de l'art numérique en général.


\end{spacing}
\keywordsFR{\textit{livecoding}, \textit{demoscene}, \textit{algorave}, \textit{fragment shaders}, \textit{pipeline}, Orca, FoxDot}
\end{abstract}
%\hspace{10pt}

\providecommand{\keywordsEN}[1]
{
  \small	
  \textbf{\textit{Keywords---}} #1
}

\renewcommand{\abstractname}{Abstract}
\begin{abstract}
\hskip7mm
\begin{spacing}{1.3}
This dissertation explores the interaction between live-coded music and real-time shader programming. Stemming from observations of livecoders' performances, where the interplay between music and shaders appears artificial, with visual variables adjusted to match the musical tempo.
To gain a deeper understanding of the demoscene's essence, I first delved into its historical evolution. Subsequently, I examined the fundamental concepts essential for real-time shader development, before delving into advanced techniques, albeit more challenging to implement live, significantly enhancing visual output.
Finally, this dissertation delves into the challenge of seamless integration between music and shaders. Through an in-depth examination of the interactions between audio and visual components, and utilizing Orca and FoxDot to generate MIDI streams and control shaders, this research aims to pave the way for new creative exploration in the demoscene and digital art at large.
\end{spacing}
\keywordsEN{\textit{livecoding}, \textit{demoscene}, \textit{algorave}, \textit{fragment shaders}, \textit{pipeline}, Orca, FoxDot}
\end{abstract}

